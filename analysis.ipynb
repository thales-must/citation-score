{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3db0b92d",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f130f930",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from dotenv import load_dotenv\n",
    "from scipy.stats import spearmanr\n",
    "import os\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07710fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "origindf = pd.read_excel('score.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78279fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CountScore:\n",
    "  \n",
    "  _df:pd.DataFrame\n",
    "  def __init__(self, df):\n",
    "    self._origin = df.copy()\n",
    "    self._model = os.getenv('LLM_MODEL')\n",
    "\n",
    "  def get_df(self):\n",
    "    return self._df\n",
    "  \n",
    "  def parse(self):\n",
    "    self._origin['count'] = np.where(self._origin['author_independence'] > 0.5, 1, 0)\n",
    "    self._origin['score'] = (self._origin[\"relevance_cross\"] * 0.5 + self._origin[self._model] * 0.5) * ((1 - 0.5) + 0.5 * self._origin[\"author_independence\"])\n",
    "    self._origin['score_raw'] = (self._origin[\"relevance_cross\"] + self._origin[self._model]) * ((1 - 0.5) + 0.5 * self._origin[\"author_independence\"])\n",
    "    mean_count = self._origin['count'].mean()\n",
    "    mean_score = self._origin['score'].mean()\n",
    "    mean_cross = self._origin['relevance_cross'].mean()\n",
    "    mean_llm = self._origin[self._model].mean()\n",
    "    self._origin['score_0_to_2_mm'] = self._origin['score'] * mean_count / mean_score\n",
    "    self._origin['cross_0_to_2'] = self._origin['relevance_cross'] * (mean_count / mean_cross)\n",
    "    self._origin['llm_0_to_2'] = self._origin[self._model] * (mean_count / mean_llm)\n",
    "    self._df = self._origin.groupby(['cited_id', 'cited_title']).agg(\n",
    "      count=('count', 'sum'),  # 引用次数\n",
    "      total_score=('score_0_to_2_mm', 'sum'),  # score总和\n",
    "    )\n",
    "    self._df = self._df[self._df['count'] > 10].reset_index()\n",
    "    self._df['diff'] = (self._df['total_score'] - self._df['count']) / self._df['count']\n",
    "  \n",
    "  def plot(self):\n",
    "    width = 0.35\n",
    "    df = self._df\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(8, 5), gridspec_kw={'height_ratios': [2, 1]})\n",
    "\n",
    "    x = np.arange(len(df['count']))\n",
    "\n",
    "    # 上子图：count 和 total_score\n",
    "    bars1 = ax1.bar(x - width/2, df['count'], width, label='Count')\n",
    "    bars2 = ax1.bar(x + width/2, df['total_score'], width, label='Score Sum')\n",
    "    ax1.set_ylabel(\"Value\")\n",
    "    ax1.set_xticks(x)\n",
    "    ax1.set_xticklabels([])\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    # ax1.set_xticklabels(df.index, rotation=45)\n",
    "    ax1.legend()\n",
    "    # ax1.set_title(\"Citation Count vs. Aggregated Citation Score\")\n",
    "\n",
    "    # 下子图：diff 作为条形高度，颜色也根据 diff 值变化\n",
    "    val = max(abs(df['diff'].min()), abs(df['diff'].max()))\n",
    "    norm = plt.Normalize(-val, val)\n",
    "    cmap = plt.cm.coolwarm\n",
    "    bars3 = ax2.bar(x, df['diff'], width, color=cmap(norm(df['diff'])), edgecolor='black')\n",
    "    ax2.set_xlabel(\"Sampled Papers\")\n",
    "    ax2.set_ylabel(\"Normalized Count-Score Gap\")\n",
    "    ax2.set_xticks(x)\n",
    "    ax2.set_xticklabels(df.index, rotation=45)\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "\n",
    "    # 添加颜色条\n",
    "    # sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "    # sm.set_array([])\n",
    "    # fig.colorbar(sm, ax=ax1, orientation='vertical', label='Normalized Discrepancy')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "  def topk(self):\n",
    "    pos_case = self._df.loc[self._df['diff'].idxmax()]\n",
    "    neg_case = self._df.loc[self._df['diff'].idxmin()]\n",
    "    bal_case = self._df[self._df['diff'].abs() < 0.02]\n",
    "    return pos_case, neg_case, bal_case\n",
    "    \n",
    "\n",
    "  def detail(self, id:str):\n",
    "    df = self._origin[self._origin['cited_id'] == id][['relevance_cross', self._model, 'author_independence','score_raw', 'count', 'score_0_to_2_mm', 'cross_0_to_2', 'llm_0_to_2']]\n",
    "    df['llm'] = df[self._model]\n",
    "    df['count_sum'] = df['count'].cumsum()\n",
    "    df['score_sum'] = df['score_0_to_2_mm'].cumsum()\n",
    "    df['cross_sum'] = df['cross_0_to_2'].cumsum()\n",
    "    df['llm_sum'] = df['llm_0_to_2'].cumsum()\n",
    "    df[\"delta\"] = df[\"score_0_to_2_mm\"] - df[\"count\"]\n",
    "    fig, axes = plt.subplots(3, 1, figsize=(8, 5), gridspec_kw={'height_ratios': [2, 1, 1]})\n",
    "    plt.subplots_adjust(wspace=0.5, hspace=0.5)\n",
    "    x = np.arange(len(df))\n",
    "    axes[0].step(x, df['count_sum'], label='Count', color='#9467bd')\n",
    "    axes[0].plot(x, df['score_sum'], label='Score', color='#d62728')\n",
    "    axes[0].plot(x, df['cross_sum'], label='Cross-only', color='#1f77b4')\n",
    "    axes[0].plot(x, df['llm_sum'], label='LLM-only', color='#ff7f0e')\n",
    "    axes[0].set_xticklabels([])\n",
    "    axes[0].set_ylabel(\"Count & Score\")\n",
    "    axes[0].set_title(\"(a) Cumulative Citation Count & Score\")\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "    \n",
    "    norm = plt.Normalize(-1, 1)\n",
    "    cmap = plt.cm.coolwarm\n",
    "    axes[1].bar(x, df[\"delta\"], color=cmap(norm(df['delta'])), edgecolor='black')\n",
    "    axes[1].axhline(0, linestyle=\"--\", color=\"black\", alpha=0.6)\n",
    "    axes[1].set_title(\"(b) Per-citation Score Deviation\")\n",
    "    axes[1].set_xticklabels([])\n",
    "    axes[1].set_ylabel(r\"$\\tilde{S}_{ij} - N_{ij}$\")\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "    axes[2].bar(x, df[\"relevance_cross\"], label=\"Cross\", color='#1f77b4')\n",
    "    axes[2].bar(x, df[\"llm\"], bottom=df[\"relevance_cross\"], label=\"LLM\", color='#ff7f0e')\n",
    "    axes[2].bar(\n",
    "        x,\n",
    "        -1 + df[\"author_independence\"],\n",
    "        # bottom=df[\"relevance_cross\"] + df[\"llm\"],\n",
    "        label=\"Author Penalty\", color='#2ca02c'\n",
    "    )\n",
    "    axes[2].axhline(1, linestyle=\"--\", color=\"black\", alpha=0.6)\n",
    "    axes[2].set_ylabel(\"Score\")\n",
    "    axes[2].set_title(\"(c) Score Components\")\n",
    "    axes[2].legend(fontsize=7, loc='upper center', bbox_to_anchor=(0.16, 1.71))\n",
    "    axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ff55db",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_score = CountScore(origindf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d994cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_score.parse()\n",
    "count_score.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0688e8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_score.topk()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeac0bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_score.detail('a9a654ea503386cbfd8bb119fc650cc3d08dc206')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb6060e",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_score.detail('10eab4b2feec2c1ec1ecb0107aac91b974445a69')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d752c109",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_score.detail('10dde76b297ae90451246138f00e92c832ecf14a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3166382",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ComparisonRelevance:\n",
    "\n",
    "  def __init__(self, df):\n",
    "    self._df = pd.DataFrame({\n",
    "      'cosine': df['relevance_cosine'],\n",
    "      'cross_encoder': df['relevance_cross']\n",
    "    })\n",
    "  \n",
    "  def get_df(self):\n",
    "    return self._df\n",
    "\n",
    "  def plot(self):\n",
    "    df = self._df\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(8, 7))\n",
    "    plt.subplots_adjust(wspace=0.5, hspace=1)  # 调整水平和垂直间距\n",
    "\n",
    "    # 1. 直方图\n",
    "    axes[0,0].hist(df['cosine'], bins=30, alpha=0.5, label='Cosine', color='blue', density=True)\n",
    "    axes[0,0].hist(df['cross_encoder'], bins=30, alpha=0.5, label='Cross-Encoder', color='red', density=True)\n",
    "    axes[0,0].set_title('(a) Distribution of Relevance Scores')\n",
    "    axes[0,0].set_xlabel('Relevance Score')\n",
    "    axes[0,0].set_ylabel('Probability Density')\n",
    "    axes[0,0].legend()\n",
    "    axes[0,0].grid(True, alpha=0.3)\n",
    "\n",
    "    # 2. 箱线图\n",
    "    box_data = [df['cosine'], df['cross_encoder']]\n",
    "    axes[0,1].boxplot(box_data, tick_labels=['Cosine', 'Cross-Encoder'])\n",
    "    axes[0,1].set_title('(b) Statistical Summary')\n",
    "    axes[0,1].set_ylabel('Relevance Score')\n",
    "    axes[0,1].grid(True, alpha=0.3)\n",
    "\n",
    "\n",
    "    # 3. 散点图\n",
    "    axes[1,0].scatter(df['cosine'], df['cross_encoder'], alpha=0.5, s=10)\n",
    "    axes[1,0].plot([0, 1], [0, 1], 'r--', alpha=0.5)\n",
    "    axes[1,0].set_xlabel('Cosine Relevance Score')\n",
    "    axes[1,0].set_ylabel('Cross-Encoder Relevance Score')\n",
    "    axes[1,0].set_title('(c) Correlation between Methods')\n",
    "    axes[1,0].grid(True, alpha=0.3)\n",
    "\n",
    "\n",
    "    # 4. 差异直方图\n",
    "    axes[1,1].hist(df['cosine'] - df['cross_encoder'], bins=30, alpha=0.7, color='purple')\n",
    "    axes[1,1].axvline(x=0, color='red', linestyle='--', alpha=0.5)\n",
    "    axes[1,1].set_title('(d) Score Differences Distribution')\n",
    "    axes[1,1].set_xlabel('Difference (Cosine - Cross-Encoder)')\n",
    "    axes[1,1].set_ylabel('Probability Density')\n",
    "    axes[1,1].grid(True, alpha=0.3)\n",
    "\n",
    "    # plt.suptitle('Comprehensive Comparison: Cosine vs Cross-Encoder Distributions', fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b50f7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "relevance = ComparisonRelevance(origindf)\n",
    "relevance.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2bdfddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RelevancePenalty:\n",
    "\n",
    "  def __init__(self, df:pd.DataFrame):\n",
    "    self._lambdas = np.arange(0.01, 0.95, 0.01)\n",
    "    self._df = df.copy()\n",
    "    self._df['score_context'] = self._df['relevance_cross'] * 0.5 + self._df['gpt-5-mini'] *0.5\n",
    "    self._df['score_abstract'] = self._df['relevance_cross_abstract'] * 0.5 + self._df['gpt-5-mini-abstract'] *0.5\n",
    "\n",
    "  def get_df(self):\n",
    "    return self._df\n",
    "  \n",
    "  def plot(self):\n",
    "\n",
    "    lambdas = self._lambdas\n",
    "    df = self._df[['score_context', 'score_abstract']]\n",
    "\n",
    "    # ---------- (a) MAE ----------\n",
    "    mae_list = []\n",
    "    for lam in lambdas:\n",
    "        diff = df['score_context'] - lam * df['score_abstract']\n",
    "        mae_list.append(np.mean(np.abs(diff)))\n",
    "\n",
    "    best_lambda = lambdas[np.argmin(mae_list)]\n",
    "\n",
    "    # ---------- (b) Spearman ----------\n",
    "    rho_list = []\n",
    "    for lam in lambdas:\n",
    "        scaled = lam * df['score_abstract']\n",
    "        rho, _ = spearmanr(df['score_context'], scaled)\n",
    "        rho_list.append(rho)\n",
    "\n",
    "    # ---------- (c) Ratio ----------\n",
    "    ratio = (df['score_abstract'] / df['score_context']) \\\n",
    "              .replace([np.inf, -np.inf], np.nan).dropna()\n",
    "\n",
    "    # ---------- (d) Mean gap ----------\n",
    "    mean_gaps = []\n",
    "    for lam in lambdas:\n",
    "        mean_gaps.append(\n",
    "            np.mean(lam * df['score_abstract'] - df['score_context'])\n",
    "        )\n",
    "\n",
    "    # ---------- Plot ----------\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(8, 7))\n",
    "\n",
    "    # (a)\n",
    "    axes[0, 0].plot(lambdas, mae_list, marker='o')\n",
    "    axes[0, 0].axvline(best_lambda, linestyle='--')\n",
    "    axes[0, 0].set_title('(a) MAE minimization')\n",
    "    axes[0, 0].set_xlabel(r'$\\lambda$')\n",
    "    axes[0, 0].set_ylabel('MAE')\n",
    "    axes[0, 0].grid(True)\n",
    "\n",
    "    # (b)\n",
    "    axes[0, 1].plot(lambdas, rho_list, marker='s')\n",
    "    axes[0, 1].set_title('(b) Rank consistency (Spearman)')\n",
    "    axes[0, 1].set_xlabel(r'$\\lambda$')\n",
    "    axes[0, 1].set_ylabel(r'$\\rho$')\n",
    "    axes[0, 1].grid(True)\n",
    "\n",
    "    # (c)\n",
    "    axes[1, 0].hist(ratio, bins=40)\n",
    "    axes[1, 0].axvline(0.8, linestyle='--')\n",
    "    axes[1, 0].set_title('(c) Abstract/context relevance ratio')\n",
    "    axes[1, 0].set_xlabel('Ratio')\n",
    "    axes[1, 0].set_ylabel('Frequency')\n",
    "\n",
    "    # (d)\n",
    "    axes[1, 1].plot(lambdas, mean_gaps)\n",
    "    axes[1, 1].axhline(-0.1, linestyle='--', label='-10% threshold', color='red')\n",
    "    axes[1, 1].axvline(0.8, linestyle='--', label=r'$\\lambda=0.8$')\n",
    "    axes[1, 1].set_title('(d) Mean penalized gap')\n",
    "    axes[1, 1].set_xlabel(r'$\\lambda$')\n",
    "    axes[1, 1].set_ylabel('Mean gap')\n",
    "    axes[1, 1].legend()\n",
    "    axes[1, 1].grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d534298",
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_penalty = RelevancePenalty(origindf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5002af3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_penalty.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67d832f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RelevanceLLM:\n",
    "\n",
    "  def __init__(self, df:pd.DataFrame):\n",
    "    self._df = df.copy()\n",
    "    self._llm_cols = [\"Cross-encoder\", \"gpt-5-mini\", \"qwen3-max\", \"deepseek-chat\", \"gemini-2.5-flash\"]\n",
    "    self._df['Cross-encoder'] = df['relevance_cross']\n",
    "\n",
    "\n",
    "  def density(self):\n",
    "    df = self._df\n",
    "    # df['gpt-4.1-mini'] = df['llm']\n",
    "\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    for col in self._llm_cols:\n",
    "        sns.kdeplot(df[col], label=col, fill=True, alpha=0.3)\n",
    "\n",
    "    plt.xlabel(\"Relevance Score\")\n",
    "    plt.ylabel(\"Density\")\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "\n",
    "  def heatmap(self):\n",
    "    df = self._df\n",
    "    corr = pd.DataFrame(index=self._llm_cols, columns=self._llm_cols)\n",
    "\n",
    "    for c1 in self._llm_cols:\n",
    "        for c2 in self._llm_cols:\n",
    "            rho, _ = spearmanr(df[c1], df[c2])\n",
    "            corr.loc[c1, c2] = rho\n",
    "\n",
    "    corr = corr.astype(float)\n",
    "\n",
    "    plt.figure(figsize=(5, 4))\n",
    "    sns.heatmap(corr, annot=True, cmap=\"coolwarm\", vmin=0, vmax=1)\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.show()\n",
    "\n",
    "  def scatter(self, col:str):\n",
    "    fig, axes = plt.subplots(figsize=(4, 3.5))\n",
    "\n",
    "    rho, _ = spearmanr(self._df[\"Cross-encoder\"], self._df[col])\n",
    "    axes.scatter(self._df[\"Cross-encoder\"], self._df[col], alpha=0.4, s=10)\n",
    "    axes.plot([0,1], [0,1], 'r--', alpha=0.5)\n",
    "    axes.set_xlabel(\"Cross-Encoder Relevance\")\n",
    "    axes.set_ylabel(\"LLM-based Relevance\")\n",
    "    axes.set_title(f\"Spearman {r'$\\rho$ '}= {rho:.2f}\")\n",
    "    axes.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "  def delta(self):\n",
    "    df = self._df[['llm', 'relevance_cross']]\n",
    "    df[\"delta\"] = df[\"llm\"] - df[\"relevance_cross\"]\n",
    "\n",
    "    top_pos = df.nlargest(5, \"delta\")\n",
    "    top_neg = df.nsmallest(5, \"delta\")\n",
    "    mid = df.iloc[(df[\"delta\"].abs()).argsort()[:5]]\n",
    "\n",
    "    subdf = pd.concat([top_pos, top_neg, mid])\n",
    "\n",
    "    # labels = subdf.index.astype(str)\n",
    "    x = np.arange(len(subdf))\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(7.2,3))\n",
    "    # fig, ax = plt.subplots(figsize=(14, 6))\n",
    "\n",
    "    # 添加垂直分割线和标签\n",
    "    ax.axvline(x=4.5, color='gray', linestyle='--', alpha=0.7, linewidth=1)\n",
    "    ax.axvline(x=9.5, color='gray', linestyle='--', alpha=0.7, linewidth=1)\n",
    "\n",
    "    # 添加区域标签\n",
    "    ax.text(2, ax.get_ylim()[1] * 1.1, 'Cross < LLM', \n",
    "            ha='center', fontsize=11, fontweight='bold', \n",
    "            bbox=dict(boxstyle='round', facecolor='#2E86AB', alpha=0.2))\n",
    "    ax.text(7, ax.get_ylim()[1] * 1.1, 'Cross > LLM', \n",
    "            ha='center', fontsize=11, fontweight='bold',\n",
    "            bbox=dict(boxstyle='round', facecolor='#6B8F71', alpha=0.2))\n",
    "    ax.text(12, ax.get_ylim()[1] * 1.1, 'Cross = LLM', \n",
    "            ha='center', fontsize=11, fontweight='bold',\n",
    "            bbox=dict(boxstyle='round', facecolor='#A23B72', alpha=0.2))\n",
    "\n",
    "    plt.bar(x - 0.15, subdf[\"relevance_cross\"], width=0.3, label=\"Cross\")\n",
    "    plt.bar(x + 0.15, subdf[\"llm\"], width=0.3, label=\"LLM\")\n",
    "    # plt.xticks(x, labels, rotation=45)\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "  def stability(self, col:str):\n",
    "    alphas = np.linspace(0, 1, 11)\n",
    "    rhos = []\n",
    "\n",
    "    for a in alphas:\n",
    "        fused = a * self._df[\"relevance_cross\"] + (1 - a) * self._df[col]\n",
    "        rho, _ = spearmanr(self._df[\"relevance_cross\"], fused)\n",
    "        rhos.append(rho)\n",
    "\n",
    "    plt.figure(figsize=(4,3.5))\n",
    "    plt.plot(alphas, rhos, marker='o')\n",
    "    plt.xlabel(r\"Weight $\\alpha$ for Cross\")\n",
    "    plt.ylabel(\"Spearman Correlation w.r.t Cross\")\n",
    "    # plt.title(\"Stability of Ranking under LLM Weighting\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86f5a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_llm = RelevanceLLM(origindf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f6849d",
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_llm.density()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fffa5614",
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_llm.heatmap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d461abdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_llm.scatter('gpt-5-mini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aee227e",
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_llm.stability('gpt-5-mini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9d3cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BetaCalibration:\n",
    "  def __init__(self, df: pd.DataFrame):\n",
    "    # 只保留会被惩罚的样本\n",
    "    self._df = df[['relevance_cross', 'gpt-5-mini', 'author_independence']].copy()\n",
    "    # self._df.iloc[0]['author_independence'] = 0.6\n",
    "    # self._df.iloc[1]['author_independence'] = 0.8\n",
    "    self._betas = np.linspace(0, 1, 51)\n",
    "\n",
    "  def distribution(self):\n",
    "    df = self._df.copy()\n",
    "    order = [0, 0.1, 0.5, 0.6, 0.8, 1.0]\n",
    "    sns.countplot(x='author_independence', data=df, order=order)\n",
    "    plt.xlabel(\"Author Independence Level\")\n",
    "    plt.ylabel(\"Number of Citations\")\n",
    "    plt.show()\n",
    "\n",
    "  def evaluate(self, extract = None):\n",
    "    avg_drop = []\n",
    "    rank_rho = []\n",
    "\n",
    "    df = self._df.copy()\n",
    "    if extract:\n",
    "      df = df[df['author_independence']<1]\n",
    "    \n",
    "    df['base'] = df[\"relevance_cross\"] * 0.5 + df[\"gpt-5-mini\"] * 0.5\n",
    "\n",
    "    for beta in self._betas:\n",
    "      penalty = (1 - beta) + beta * df[\"author_independence\"]\n",
    "      final = df['base'] * penalty\n",
    "      \n",
    "      # 相对降幅\n",
    "      drop = (final - df['base']) / df['base']\n",
    "      avg_drop.append(drop.mean())\n",
    "\n",
    "      # 排序稳定性\n",
    "      rho, _ = spearmanr(df['base'], final)\n",
    "      rank_rho.append(rho)\n",
    "\n",
    "    return pd.DataFrame({\n",
    "      \"beta\": self._betas,\n",
    "      \"avg_relative_drop\": avg_drop,\n",
    "      \"spearman_rho\": rank_rho\n",
    "    })\n",
    "\n",
    "  def plot(self, res):\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(8, 3.5))\n",
    "\n",
    "    # (a) 平均惩罚幅度\n",
    "    axes[0].plot(res[\"beta\"], -res[\"avg_relative_drop\"], marker=\"o\")\n",
    "    axes[0].axhline(0.3, linestyle=\"--\", color=\"gray\", label=\"30% drop\")\n",
    "    axes[0].set_xlabel(r\"$\\beta$\")\n",
    "    axes[0].set_ylim(0, 1)\n",
    "    axes[0].set_ylabel(\"Average Relative Penalty\")\n",
    "    axes[0].set_title(\"(a) Penalty Magnitude\")\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True)\n",
    "\n",
    "    # (b) 排序稳定性\n",
    "    axes[1].plot(res[\"beta\"], res[\"spearman_rho\"], marker=\"s\")\n",
    "    axes[1].axhline(0.9, linestyle=\"--\", color=\"gray\", label=r\"$\\rho=0.9$\")\n",
    "    axes[1].set_xlabel(r\"$\\beta$\")\n",
    "    axes[1].set_ylim(0, 1)\n",
    "    axes[1].set_ylabel(\"Spearman Correlation\")\n",
    "    axes[1].set_title(\"(b) Rank Stability\")\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4873d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_instance = BetaCalibration(origindf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c057e511",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_instance.plot( beta_instance.evaluate() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47129dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_instance.plot( beta_instance.evaluate(True) )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "latex",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
